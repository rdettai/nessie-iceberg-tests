{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessie Demo\n",
    "===========\n",
    "This demo showcases how to use Nessie python API along with Spark3 from Iceberg\n",
    "\n",
    "Initialize Pyspark + Nessie environment\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from py4j.java_gateway import java_import\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .config(\"spark.sql.execution.pyarrow.enabled\", \"true\") \\\n",
    "                    .config(\"spark.hadoop.fs.defaultFS\", 'file://' + os.getcwd() + '/spark_warehouse') \\\n",
    "                    .config(\"spark.hadoop.nessie.url\", os.getenv(\"NESSIE_ENDPOINT\")) \\\n",
    "                    .config(\"spark.hadoop.nessie.ref\", \"main\") \\\n",
    "                    .config(\"spark.sql.catalog.nessie\", \"com.dremio.nessie.iceberg.spark.NessieIcebergSparkCatalog\") \\\n",
    "                    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "jvm = sc._gateway.jvm\n",
    "\n",
    "java_import(jvm, \"com.dremio.nessie.iceberg.NessieCatalog\")\n",
    "java_import(jvm, \"org.apache.iceberg.catalog.TableIdentifier\")\n",
    "java_import(jvm, \"org.apache.iceberg.Schema\")\n",
    "java_import(jvm, \"org.apache.iceberg.types.Types\")\n",
    "java_import(jvm, \"org.apache.iceberg.PartitionSpec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up nessie branches\n",
    "----------------------------\n",
    "\n",
    "- Branch `main` already exists\n",
    "- Create branch `dev`\n",
    "- List all branches (pipe JSON result into jq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie branch dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m* main  e0b41c30f0710277532f51242994e10acfdc46bf comment\r\n",
      "\u001b[0m  dev   e0b41c30f0710277532f51242994e10acfdc46bf comment\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tables under dev branch\n",
    "-------------------------------------\n",
    "\n",
    "Creating two tables under the `dev` branch:\n",
    "- region\n",
    "- nation\n",
    "\n",
    "It is not yet possible to create table using pyspark and iceberg, so Java code\n",
    "is used instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"nessie.ref\", \"dev\")\n",
    "catalog = jvm.NessieCatalog(sc._jsc.hadoopConfiguration())\n",
    "\n",
    "# Creating region table\n",
    "region_name = jvm.TableIdentifier.parse(\"testing.region\")\n",
    "region_schema = jvm.Schema([\n",
    "    jvm.Types.NestedField.optional(1, \"R_REGIONKEY\", jvm.Types.LongType.get()),\n",
    "    jvm.Types.NestedField.optional(2, \"R_NAME\", jvm.Types.StringType.get()),\n",
    "    jvm.Types.NestedField.optional(3, \"R_COMMENT\", jvm.Types.StringType.get()),\n",
    "])\n",
    "region_spec = jvm.PartitionSpec.unpartitioned()\n",
    "\n",
    "region_table = catalog.createTable(region_name, region_schema, region_spec)\n",
    "region_df = spark.read.load(\"data/region.parquet\")\n",
    "region_df.write.option('hadoop.nessie.ref', 'dev').format(\"iceberg\").mode(\"overwrite\").save(\"testing.region\")\n",
    "\n",
    "# Creating nation table\n",
    "nation_name = jvm.TableIdentifier.parse(\"testing.nation\")\n",
    "nation_schema = jvm.Schema([\n",
    "    jvm.Types.NestedField.optional(1, \"N_NATIONKEY\", jvm.Types.LongType.get()),\n",
    "    jvm.Types.NestedField.optional(2, \"N_NAME\", jvm.Types.StringType.get()),\n",
    "    jvm.Types.NestedField.optional(3, \"N_REGIONKEY\", jvm.Types.LongType.get()),\n",
    "    jvm.Types.NestedField.optional(4, \"N_COMMENT\", jvm.Types.StringType.get()),\n",
    "])\n",
    "nation_spec = jvm.PartitionSpec.builderFor(nation_schema).truncate(\"N_NAME\", 2).build()\n",
    "nation_table = catalog.createTable(nation_name, nation_schema, nation_spec)\n",
    "\n",
    "nation_df = spark.read.load(\"data/nation.parquet\")\n",
    "nation_df.write.option('hadoop.nessie.ref', 'dev').format(\"iceberg\").mode(\"overwrite\").save(\"testing.nation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check generated tables\n",
    "----------------------------\n",
    "\n",
    "Check tables generated under the dev branch (and that the main branch does not\n",
    "have any tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie contents --list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN:\r\n",
      "\ttesting.nation\r\n",
      "\ttesting.region\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie contents --list --ref dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `dev` and `main` branches point to different commits now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m* main  e0b41c30f0710277532f51242994e10acfdc46bf comment\r\n",
      "\u001b[0m  dev   b7dd56f9ea974fb62ee7d50813464d51a438f205 comment\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dev promotion\n",
    "-------------\n",
    "\n",
    "Promote dev branch promotion to main.\n",
    "\n",
    "* main now has the same tables as dev\n",
    "* main and dev point to the same commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie merge dev --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN:\r\n",
      "\ttesting.nation\r\n",
      "\ttesting.region\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie contents --list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m* main  b7dd56f9ea974fb62ee7d50813464d51a438f205 comment\r\n",
      "\u001b[0m  dev   b7dd56f9ea974fb62ee7d50813464d51a438f205 comment\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `etl` branch\n",
    "----------------------\n",
    "\n",
    "- Create a branch `etl` out of `main`\n",
    "- add data to nation\n",
    "- alter the schema of region\n",
    "- create table city\n",
    "- query the tables in `etl`\n",
    "- query the tables in `main`\n",
    "- promote `etl` branch to `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie branch etl main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nation = Row(\"N_NATIONKEY\", \"N_NAME\", \"N_REGIONKEY\", \"N_COMMENT\")\n",
    "new_nations = spark.createDataFrame([\n",
    "    Nation(25, \"SYLDAVIA\", 3, \"King Ottokar's Sceptre\"),\n",
    "    Nation(26, \"SAN THEODOROS\", 1, \"The Picaros\")])\n",
    "new_nations.write.option('hadoop.nessie.ref', 'etl').format(\"iceberg\").mode(\"append\").save(\"testing.nation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m* main  b7dd56f9ea974fb62ee7d50813464d51a438f205 comment\r\n",
      "\u001b[0m  dev   b7dd56f9ea974fb62ee7d50813464d51a438f205 comment\r\n",
      "  etl   db44e81a4762fb4c479135bb397c097811cee2fd comment\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the default branch\n",
    "hadoop_conf.set('nessie.ref', 'etl')\n",
    "\n",
    "etl_catalog = jvm.NessieCatalog(hadoop_conf)\n",
    "etl_catalog.loadTable(region_name).updateSchema().addColumn('R_ABBREV', jvm.Types.StringType.get()).commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m* main  b7dd56f9ea974fb62ee7d50813464d51a438f205 comment\r\n",
      "\u001b[0m  dev   b7dd56f9ea974fb62ee7d50813464d51a438f205 comment\r\n",
      "  etl   87ebd562faf6d3a7d39c934d8ad393b62825b31c comment\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating city table\n",
    "sc.getConf().set(\"spark.hadoop.nessie.ref\", \"etl\")\n",
    "spark.sql(\"CREATE TABLE nessie.testing.city (C_CITYKEY BIGINT, C_NAME STRING, N_NATIONKEY BIGINT, C_COMMNT STRING) USING iceberg PARTITIONED BY (N_NATIONKEY)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m* main  b7dd56f9ea974fb62ee7d50813464d51a438f205 comment\r\n",
      "\u001b[0m  dev   b7dd56f9ea974fb62ee7d50813464d51a438f205 comment\r\n",
      "  etl   c3065a3d139b96bb882f723908de1d59664713b1 comment\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Entry(kind='UNKNOWN', name=EntryName(elements=['testing', 'nation'])),\n",
       " Entry(kind='UNKNOWN', name=EntryName(elements=['testing', 'region']))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pynessie import init\n",
    "nessie = init()\n",
    "nessie.list_keys('main').entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EntryName(elements=['testing', 'nation']),\n",
       " EntryName(elements=['testing', 'city']),\n",
       " EntryName(elements=['testing', 'region'])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.name for i in nessie.list_keys('etl').entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main': 'b7dd56f9ea974fb62ee7d50813464d51a438f205',\n",
       " 'dev': 'b7dd56f9ea974fb62ee7d50813464d51a438f205',\n",
       " 'etl': 'c3065a3d139b96bb882f723908de1d59664713b1'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i.name:i.hash_ for i in nessie.list_references()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NessieConflictException",
     "evalue": "Entity already exists at : 409 Client Error: Conflict for url: http://nessie:19120/api/v1/trees/branch/main/merge?expectedHash=b7dd56f9ea974fb62ee7d50813464d51a438f205",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNessieConflictException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b4778820b66b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnessie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'main'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'etl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pynessie/nessie_client.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, branch, to_branch, old_hash)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mto_hash\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mmerge_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMergeSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_hash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl_verify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcherry_pick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"NessieClient\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_hash\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mhashes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pynessie/_endpoints.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(base_url, branch, merge_json, expected_hash, ssl_verify)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/trees/branch/{}/merge\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"expectedHash\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexpected_hash\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl_verify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mssl_verify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pynessie/_endpoints.py\u001b[0m in \u001b[0;36m_post\u001b[0;34m(url, json, details, ssl_verify, params)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mssl_verify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_check_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pynessie/_endpoints.py\u001b[0m in \u001b[0;36m_check_error\u001b[0;34m(r, details)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNessieNotFoundException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No entity exists at \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m409\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNessieConflictException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Entity already exists at \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNessieServerException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Server error at \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNessieConflictException\u001b[0m: Entity already exists at : 409 Client Error: Conflict for url: http://nessie:19120/api/v1/trees/branch/main/merge?expectedHash=b7dd56f9ea974fb62ee7d50813464d51a438f205"
     ]
    }
   ],
   "source": [
    "nessie.merge('main', 'etl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mNessie Exception\u001b[0m is Entity already exists at : 409 Client Error: Conflict for url: http://nessie:19120/api/v1/trees/branch/main/merge?expectedHash=b7dd56f9ea974fb62ee7d50813464d51a438f205 with status code: 409.\n",
      "\u001b[33mServer status:\u001b[0m CONFLICT\n",
      "\u001b[33mServer message:\u001b[0m The branch [main] does not have the expected hash [b7dd56f9ea974fb62ee7d50813464d51a438f205].\n",
      "\u001b[33mServer traceback:\u001b[0m com.dremio.nessie.error.NessieConflictException: The branch [main] does not have the expected hash [b7dd56f9ea974fb62ee7d50813464d51a438f205].\n",
      "\tat com.dremio.nessie.services.rest.TreeResource.mergeRefIntoBranch(TreeResource.java:207)\n",
      "\tat com.dremio.nessie.services.rest.TreeResource_Subclass.mergeRefIntoBranch$$superaccessor11(TreeResource_Subclass.zig:2998)\n",
      "\tat com.dremio.nessie.services.rest.TreeResource_Subclass$$function$$11.apply(TreeResource_Subclass$$function$$11.zig:47)\n",
      "\tat io.quarkus.arc.impl.AroundInvokeInvocationContext.proceed(AroundInvokeInvocationContext.java:54)\n",
      "\tat io.quarkus.hibernate.validator.runtime.interceptor.AbstractMethodValidationInterceptor.validateMethodInvocation(AbstractMethodValidationInterceptor.java:69)\n",
      "\tat io.quarkus.hibernate.validator.runtime.jaxrs.JaxrsEndPointValidationInterceptor.validateMethodInvocation(JaxrsEndPointValidationInterceptor.java:32)\n",
      "\tat io.quarkus.hibernate.validator.runtime.jaxrs.JaxrsEndPointValidationInterceptor_Bean.intercept(JaxrsEndPointValidationInterceptor_Bean.zig:341)\n",
      "\tat io.quarkus.arc.impl.InterceptorInvocation.invoke(InterceptorInvocation.java:41)\n",
      "\tat io.quarkus.arc.impl.AroundInvokeInvocationContext.proceed(AroundInvokeInvocationContext.java:50)\n",
      "\tat io.quarkus.micrometer.runtime.binder.mpmetrics.TimedInterceptor.time(TimedInterceptor.java:54)\n",
      "\tat io.quarkus.micrometer.runtime.binder.mpmetrics.TimedInterceptor.timedMethod(TimedInterceptor.java:35)\n",
      "\tat io.quarkus.micrometer.runtime.binder.mpmetrics.TimedInterceptor_Bean.intercept(TimedInterceptor_Bean.zig:326)\n",
      "\tat io.quarkus.arc.impl.InterceptorInvocation.invoke(InterceptorInvocation.java:41)\n",
      "\tat io.quarkus.arc.impl.AroundInvokeInvocationContext.proceed(AroundInvokeInvocationContext.java:50)\n",
      "\tat io.quarkus.micrometer.runtime.binder.mpmetrics.CountedInterceptor.increment(CountedInterceptor.java:51)\n",
      "\tat io.quarkus.micrometer.runtime.binder.mpmetrics.CountedInterceptor.countedMethod(CountedInterceptor.java:33)\n",
      "\tat io.quarkus.micrometer.runtime.binder.mpmetrics.CountedInterceptor_Bean.intercept(CountedInterceptor_Bean.zig:326)\n",
      "\tat io.quarkus.arc.impl.InterceptorInvocation.invoke(InterceptorInvocation.java:41)\n",
      "\tat io.quarkus.arc.impl.AroundInvokeInvocationContext.perform(AroundInvokeInvocationContext.java:41)\n",
      "\tat io.quarkus.arc.impl.InvocationContexts.performAroundInvoke(InvocationContexts.java:32)\n",
      "\tat com.dremio.nessie.services.rest.TreeResource_Subclass.mergeRefIntoBranch(TreeResource_Subclass.zig:2933)\n",
      "\tat com.dremio.nessie.services.rest.TreeResource_ClientProxy.mergeRefIntoBranch(TreeResource_ClientProxy.zig:706)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:170)\n",
      "\tat org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:130)\n",
      "\tat org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:643)\n",
      "\tat org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:507)\n",
      "\tat org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$2(ResourceMethodInvoker.java:457)\n",
      "\tat org.jboss.resteasy.core.interception.jaxrs.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:364)\n",
      "\tat org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:459)\n",
      "\tat org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:419)\n",
      "\tat org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:393)\n",
      "\tat org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:68)\n",
      "\tat org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:492)\n",
      "\tat org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:261)\n",
      "\tat org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:161)\n",
      "\tat org.jboss.resteasy.core.interception.jaxrs.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:364)\n",
      "\tat org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:164)\n",
      "\tat org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:247)\n",
      "\tat io.quarkus.resteasy.runtime.standalone.RequestDispatcher.service(RequestDispatcher.java:73)\n",
      "\tat io.quarkus.resteasy.runtime.standalone.VertxRequestHandler.dispatch(VertxRequestHandler.java:131)\n",
      "\tat io.quarkus.resteasy.runtime.standalone.VertxRequestHandler.access$000(VertxRequestHandler.java:37)\n",
      "\tat io.quarkus.resteasy.runtime.standalone.VertxRequestHandler$1.run(VertxRequestHandler.java:94)\n",
      "\tat org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)\n",
      "\tat org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2046)\n",
      "\tat org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1578)\n",
      "\tat org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1452)\n",
      "\tat org.jboss.threads.DelegatingRunnable.run(DelegatingRunnable.java:29)\n",
      "\tat org.jboss.threads.ThreadLocalResettingRunnable.run(ThreadLocalResettingRunnable.java:29)\n",
      "\tat java.lang.Thread.run(Thread.java:834)\n",
      "\tat org.jboss.threads.JBossThread.run(JBossThread.java:479)\n",
      "\tat com.oracle.svm.core.thread.JavaThreads.threadStartRoutine(JavaThreads.java:517)\n",
      "\tat com.oracle.svm.core.posix.thread.PosixJavaThreads.pthreadStartRoutine(PosixJavaThreads.java:192)\n",
      "Caused by: com.dremio.nessie.versioned.ReferenceConflictException: The following keys have been changed in conflict: testing.nation [131:116], testing.region [141:44].\n",
      "\tat com.dremio.nessie.versioned.impl.TieredVersionStore.internalTransplant(TieredVersionStore.java:582)\n",
      "\tat com.dremio.nessie.versioned.impl.TieredVersionStore.merge(TieredVersionStore.java:484)\n",
      "\tat com.dremio.nessie.services.rest.TreeResource.mergeRefIntoBranch(TreeResource.java:202)\n",
      "\t... 52 more\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nessie merge etl --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main': 'b7dd56f9ea974fb62ee7d50813464d51a438f205',\n",
       " 'dev': 'b7dd56f9ea974fb62ee7d50813464d51a438f205',\n",
       " 'etl': 'c3065a3d139b96bb882f723908de1d59664713b1'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i.name:i.hash_ for i in nessie.list_references()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `experiment` branch\n",
    "--------------------------------\n",
    "\n",
    "- create `experiment` branch from `main`\n",
    "- drop `nation` table\n",
    "- add data to `region` table\n",
    "- compare `experiment` and `main` tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie branch experiment main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the default branch\n",
    "hadoop_conf.set('nessie.ref', 'experiment')\n",
    "\n",
    "catalog = jvm.NessieCatalog(hadoop_conf)\n",
    "catalog.dropTable(jvm.TableIdentifier.parse(\"testing.nation\"), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"set spark.hadoop.nessie.ref=experiment\")\n",
    "spark.sql('INSERT INTO TABLE nessie.testing.region VALUES (5, \"AUSTRALIA\", \"Let\\'s hop there\", \"AUS\")')\n",
    "spark.sql('INSERT INTO TABLE nessie.testing.region VALUES (6, \"ANTARTICA\", \"It\\'s cold\", \"ANT\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN:\r\n",
      "\ttesting.region\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie contents --list --ref experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the contents of the region table on the experiment branch.\n",
    "Notice the use of the `nessie` catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_REGIONKEY</th>\n",
       "      <th>R_NAME</th>\n",
       "      <th>R_COMMENT</th>\n",
       "      <th>R_ABBREV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>lar deposits. blithely final packages cajole. ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AMERICA</td>\n",
       "      <td>hs use ironic, even requests. s</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>ges. thinly even pinto beans ca</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>EUROPE</td>\n",
       "      <td>ly final courts cajole furiously final excuse</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MIDDLE EAST</td>\n",
       "      <td>uickly special accounts cajole carefully blith...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Let's hop there</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>ANTARTICA</td>\n",
       "      <td>It's cold</td>\n",
       "      <td>ANT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R_REGIONKEY       R_NAME  \\\n",
       "0            0       AFRICA   \n",
       "1            1      AMERICA   \n",
       "2            2         ASIA   \n",
       "3            3       EUROPE   \n",
       "4            4  MIDDLE EAST   \n",
       "5            5    AUSTRALIA   \n",
       "6            6    ANTARTICA   \n",
       "\n",
       "                                           R_COMMENT R_ABBREV  \n",
       "0  lar deposits. blithely final packages cajole. ...     None  \n",
       "1                    hs use ironic, even requests. s     None  \n",
       "2                    ges. thinly even pinto beans ca     None  \n",
       "3      ly final courts cajole furiously final excuse     None  \n",
       "4  uickly special accounts cajole carefully blith...     None  \n",
       "5                                    Let's hop there      AUS  \n",
       "6                                          It's cold      ANT  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from nessie.testing.`region`\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and compare to the contents of the region table on the main branch. Notice the\n",
    "use of `@main` to view data on the main branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_REGIONKEY</th>\n",
       "      <th>R_NAME</th>\n",
       "      <th>R_COMMENT</th>\n",
       "      <th>R_ABBREV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>lar deposits. blithely final packages cajole. ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AMERICA</td>\n",
       "      <td>hs use ironic, even requests. s</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>ges. thinly even pinto beans ca</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>EUROPE</td>\n",
       "      <td>ly final courts cajole furiously final excuse</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MIDDLE EAST</td>\n",
       "      <td>uickly special accounts cajole carefully blith...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Let's hop there</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>ANTARTICA</td>\n",
       "      <td>It's cold</td>\n",
       "      <td>ANT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R_REGIONKEY       R_NAME  \\\n",
       "0            0       AFRICA   \n",
       "1            1      AMERICA   \n",
       "2            2         ASIA   \n",
       "3            3       EUROPE   \n",
       "4            4  MIDDLE EAST   \n",
       "5            5    AUSTRALIA   \n",
       "6            6    ANTARTICA   \n",
       "\n",
       "                                           R_COMMENT R_ABBREV  \n",
       "0  lar deposits. blithely final packages cajole. ...     None  \n",
       "1                    hs use ironic, even requests. s     None  \n",
       "2                    ges. thinly even pinto beans ca     None  \n",
       "3      ly final courts cajole furiously final excuse     None  \n",
       "4  uickly special accounts cajole carefully blith...     None  \n",
       "5                                    Let's hop there      AUS  \n",
       "6                                          It's cold      ANT  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from nessie.testing.`region@etl`\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  experiment  8679b0d54540fe40e0254f4c64cecc724ddd854e comment\r\n",
      "\u001b[33m* main        b7dd56f9ea974fb62ee7d50813464d51a438f205 comment\r\n",
      "\u001b[0m  dev         b7dd56f9ea974fb62ee7d50813464d51a438f205 comment\r\n",
      "  etl         0e5c4fedab0c559fa4727dd201ac7a7e503188b6 comment\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nessie --verbose branch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
